[MLP]
layers = [13, 256, 3]
activation = Relu
na_handling_method = average
data_normalization = True
batch_norm = False

[TRAINING]
k_fold = 5
batch_size = 64
num_epochs = 30
